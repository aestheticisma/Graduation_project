## Results

### 词向量+LSTM
| 词向量+LSTM | Acc | Pr | Re | F1 | Trainable | epoch |
| -------------- | -------- | -------- | -------- | -------- | -------- | -------- |
| 自训练word2vec(100d) | 0.625731 | 0.522778 | 0.226636 | 0.292154 | False | 50 |
| 自训练word2vec(100d) | 0.606561 | 0.465614 | 0.492967 | 0.460935 | True | 50 |
| 预训练glove(100d)    | 0.624939 | 0.501283 | 0.431366 | 0.440754 | False | 50 |
| 预训练glove(100d)    | 0.605527 | 0.471022 | 0.476533 | 0.456550 | True | 50 |
| 预训练wiki word2vec(100d)    | 0.630228 | 0.506221 | 0.436347 | 0.449099 | False | 50 |
| 预训练wiki word2vec(100d)    | 0.620865 | 0.479311 | 0.505142 | 0.475388 | True | 50 |
| fasttext(100d) | 0.655658 | 0.578113 | 0.264163 | 0.350707 | False | 50 |
| fasttext(100d) | 0.607963 | 0.469200 | 0.487640 | 0.457745 | True | 50 |
| Bert(768d) | 0.638890 | 0.526669 | 0.435295 | 0.456044 | False | 50 |

### 词向量+BiLSTM+Attention
| BiLSTM+Attention | Acc | Pr | Re | F1 | Trainable | epoch |
| -------------- | -------- | -------- | -------- | -------- | -------- | -------- |
| 自训练word2vec(100d) | 0.550377 | 0.387168 | 0.411409 | 0.318356 | False | 50 |
| 自训练word2vec(100d) | 0.615195 | 0.469567 | 0.462391 | 0.452179 | True | 50 |
| 预训练glove(100d)    | 0.626574 | 0.490117 | 0.427404 | 0.434027 | False | 50 |
| 预训练glove(100d)    | 0.628894 | 0.491970 | 0.459465 | 0.460355 | True | 50 |
| 预训练wiki word2vec(100d)    | 0.614981 | 0.484167 | 0.392920 | 0.418057 | False | 50 |
| 预训练wiki word2vec(100d)    | 0.609992 | 0.479359 | 0.476048 | 0.457980 | True | 50 |
| fasttext(100d) | 0.643080 | 0.578887 | 0.199503 | 0.273452 | False | 50 |
| fasttext(100d) | 0.596023 | 0.460059 | 0.477553 | 0.447600 | True | 50 |
| Bert(768d) | 0.611617 | 0.481483 | 0.435302 | 0.437862 | False | 50 |

### 词向量+TextCNN(待更新实验结果)
| 词向量+TextCNN | Acc | Pr | Re | F1 | Trainable | epoch |
| -------------- | -------- | -------- | -------- | -------- | -------- | -------- |
| Bert(768d) | 0.647770 | 0.546336 | 0.424537 | 0.459964 | False | 50 |

## Some Records

### 1. 关于词向量

本实验共使用了

* 基于SDS数据集训练的word2vec
* 预训练的glove_100d (这个我忘记从哪下载的了 hxd对8起)
* 预训练的wiki_word2vec_100d [下载地址](https://wikipedia2vec.github.io/wikipedia2vec/pretrained/)
* 基于SDS数据集训练的fasttext_100d
* 通过`Bert-as-service`获取的Bert_768d词嵌入 使用同上一级页面的[Bert句向量获取](../Bert#调用bert-as-service获取句向量)

通过`main.py`中的options进行选择。

### 2. 关于模型

本实验共使用了

* LSTM (代码里直接换成了BiLSTM，但实验结果还是用的LSTM的，懒的改了)
* BiLSTM+Attention
* TextCNN (只跑了一个Bert_768d的，其他的词向量的结果还没来得及跑)









