## Results

### 词向量+LSTM
| 词向量+LSTM | Acc | Pr | Re | F1 | Trainable | epoch |
| -------------- | -------- | -------- | -------- | -------- | -------- | -------- |
| 自训练word2vec(100d) | 0.625731 | 0.522778 | 0.226636 | 0.292154 | False | 50 |
| 自训练word2vec(100d) | 0.606561 | 0.465614 | 0.492967 | 0.460935 | True | 50 |
| 预训练glove(100d)    | 0.624939 | 0.501283 | 0.431366 | 0.440754 | False | 50 |
| 预训练glove(100d)    | 0.605527 | 0.471022 | 0.476533 | 0.456550 | True | 50 |
| 预训练wiki word2vec(100d)    | 0.630228 | 0.506221 | 0.436347 | 0.449099 | False | 50 |
| 预训练wiki word2vec(100d)    | 0.620865 | 0.479311 | 0.505142 | 0.475388 | True | 50 |
| fasttext(100d) | 0.655658 | 0.578113 | 0.264163 | 0.350707 | False | 50 |
| fasttext(100d) | 0.607963 | 0.469200 | 0.487640 | 0.457745 | True | 50 |
| Bert(768d) | 0.638890 | 0.526669 | 0.435295 | 0.456044 | False | 50 |

### 词向量+BiLSTM+Attention
| BiLSTM+Attention | Acc | Pr | Re | F1 | Trainable | epoch |
| -------------- | -------- | -------- | -------- | -------- | -------- | -------- |
| 自训练word2vec(100d) | 0.594484 | 0.411021 | 0.194717 | 0.252234 | False | 50 |
| 自训练word2vec(100d) | 0.630865 | 0.511518 | 0.287036 | 0.355171 | True | 50 |
| 预训练glove(100d)    | 0.617624 | 0.508118 | 0.216726 | 0.288202 | False | 50 |
| 预训练glove(100d)    | 0.625258 | 0.511204 | 0.261211 | 0.331538 | True | 50 |
| 预训练wiki word2vec(100d)    | 0.622811 | 0.479011 | 0.241808 | 0.306475 | False | 50 |
| 预训练wiki word2vec(100d)    | 0.609992 | 0.479359 | 0.476048 | 0.457980 | True | 50 |
| fasttext(100d) | 0.637248 | 0.566077| 0.182606 | 0.265081 | False | 50 |
| fasttext(100d) | 0.618331 | 0.489203 | 0.281450 | 0.340978 | True | 50 |

### 词向量+TextCNN(待更新实验结果)
| Dataset | 词向量+TextCNN | Acc | Pr | Re | F1 | Trainable | epoch |
| ------ | -------------- | -------- | -------- | -------- | -------- | -------- | -------- |
| SDS | 自训练word2vec(100d) | 0.599138 | 0.460517 | 0.274916 | 0.329898 | False | 50 |
| SDS | 自训练word2vec(100d) | 0.629213 | 0.514082 | 0.291974 | 0.358257 | True | 50 |
| SDS | 自训练fasttext(100d) | 0.626891 | 0.534870 | 0.168099 | 0.245896 | False | 50 |
| SDS | 自训练fasttext(100d) | 0.621121 | 0.500141 | 0.272007| 0.336070 | True | 50 |
| SDS | 预训练glove(100d)(100d) | 0.624519 | 0.513552 | 0.261986 | 0.330023 | False | 50 |
| SDS | 预训练glove(100d)(100d) | 0.637153 | 0.533213 | 0.290446 | 0.362039 | True | 50 |

### Bert
| Dataset | 方式 | Acc | Pr | Re | F1 | Trainable | epoch |
| ------ | -------------- | -------- | -------- | -------- | -------- | -------- | -------- |
| SDS | 提取特征+Dense | 0.684022 | 0.630039 | 0.309357 | 0.397258 | False | 50 |
| SDS | 提取特征+TextCnn | 0.675988 | 0.600909 | 0.296789 | 0.378142 | False | 50 |
| SDS | 提取特征+BiLSTM | 0.671320 | 0.590214 | 0.300830 | 0.378835 | False | 50 |
| SDS | 提取特征+BiLSTM+Attention | 0.673399 | 0.595025 | 0.300186 | 0.380878 | False | 50 |

## Some Records

### 1. 关于词向量

本实验共使用了

* 基于SDS数据集训练的word2vec
* 预训练的glove_100d (这个我忘记从哪下载的了 hxd对8起)
* 预训练的wiki_word2vec_100d [下载地址](https://wikipedia2vec.github.io/wikipedia2vec/pretrained/)
* 基于SDS数据集训练的fasttext_100d
* 通过`Bert-as-service`获取的Bert_768d词嵌入 使用同上一级页面的[Bert句向量获取](../Bert#调用bert-as-service获取句向量)

通过`main.py`中的options进行选择。

### 2. 关于模型

本实验共使用了

* LSTM (代码里直接换成了BiLSTM，但实验结果还是用的LSTM的，懒的改了)
* BiLSTM+Attention
* TextCNN (只跑了一个Bert_768d的，其他的词向量的结果还没来得及跑)









